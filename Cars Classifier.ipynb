{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset link is mentioned below:\n",
    "https://www.kaggle.com/ajaykgp12/cars-wagonr-swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "img_rows = 100\n",
    "img_cols = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/users/dipit/Desktop/Python/CNN/CarsData/train\"\n",
    "validation_data_dir = '/users/dipit/Desktop/Python/CNN/CarsData/validation'\n",
    "test_data_dir = '/users/dipit/Desktop/Python/CNN/CarsData/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  width_shift_range = 0.3,\n",
    "                                  height_shift_range = 0.3,\n",
    "                                  rotation_range = 0.3,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_data_dir,\n",
    "                                                   target_size = (img_rows,img_cols),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(directory = validation_data_dir,\n",
    "                                                             target_size = (img_rows,img_cols),\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             shuffle = False,\n",
    "                                                             class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(directory = test_data_dir,\n",
    "                                                 target_size = (img_rows,img_cols),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = False,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet():\n",
    "    model = Sequential([\n",
    "    Conv2D(32,(3,3),padding = 'same',activation = 'relu',input_shape = (img_rows,img_cols,3)),\n",
    "    Conv2D(32,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Conv2D(64,(3,3),padding = 'same',activation = 'relu'),\n",
    "    Conv2D(64,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "        \n",
    "    Conv2D(128,(3,3),padding = 'same',activation = 'relu'),\n",
    "    Conv2D(64,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(num_classes,activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 49, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 21, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                204832    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 418,114\n",
      "Trainable params: 418,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= convnet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint = ModelCheckpoint(\"car_classifier_model.h5\",\\n                            monitor = \\'val_accuracy\\',\\n                            mode = \\'max\\',\\n                            save_best_only = True,\\n                            verbose = 1)\\nearlystop = EarlyStopping(monitor = \\'val_accuracy\\',\\n                         min_delta = 0,\\n                         patience = 3,\\n                         verbose = 1,\\n                         restore_best_weights = True)\\nreduce_lr = ReduceLROnPlateau(monitor = \\'val_accuracy\\',\\n                             factor = 0.2,\\n                             patience = 3,\\n                             verbose = 1,\\n                             min_delta = 0.0001)\\ncallbacks = [checkpoint,earlystop,reduce_lr]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"checkpoint = ModelCheckpoint(\"car_classifier_model.h5\",\n",
    "                            monitor = 'val_accuracy',\n",
    "                            mode = 'max',\n",
    "                            save_best_only = True,\n",
    "                            verbose = 1)\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy',\n",
    "                         min_delta = 0,\n",
    "                         patience = 3,\n",
    "                         verbose = 1,\n",
    "                         restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                             factor = 0.2,\n",
    "                             patience = 3,\n",
    "                             verbose = 1,\n",
    "                             min_delta = 0.0001)\n",
    "callbacks = [checkpoint,earlystop,reduce_lr]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 800\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 84s 1s/step - loss: 0.7055 - accuracy: 0.5021 - val_loss: 0.7221 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 83s 1s/step - loss: 0.7090 - accuracy: 0.4946 - val_loss: 0.6687 - val_accuracy: 0.5088\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 82s 1s/step - loss: 0.6969 - accuracy: 0.5188 - val_loss: 0.6835 - val_accuracy: 0.5263\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.6852 - accuracy: 0.5263 - val_loss: 0.7296 - val_accuracy: 0.5275\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.7240 - accuracy: 0.5296 - val_loss: 0.6651 - val_accuracy: 0.5263\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 81s 1s/step - loss: 0.6811 - accuracy: 0.5271 - val_loss: 0.6528 - val_accuracy: 0.5263\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 81s 1s/step - loss: 0.6872 - accuracy: 0.5342 - val_loss: 0.6621 - val_accuracy: 0.5263\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 81s 1s/step - loss: 0.6864 - accuracy: 0.5250 - val_loss: 0.6268 - val_accuracy: 0.5163\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 81s 1s/step - loss: 0.6844 - accuracy: 0.5317 - val_loss: 0.6501 - val_accuracy: 0.5213\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 85s 1s/step - loss: 0.6845 - accuracy: 0.5279 - val_loss: 0.7089 - val_accuracy: 0.5325\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 82s 1s/step - loss: 0.6833 - accuracy: 0.5329 - val_loss: 0.7516 - val_accuracy: 0.5025\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 83s 1s/step - loss: 0.6842 - accuracy: 0.5329 - val_loss: 0.6863 - val_accuracy: 0.6062\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 83s 1s/step - loss: 0.6843 - accuracy: 0.5421 - val_loss: 0.7084 - val_accuracy: 0.5512\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 86s 1s/step - loss: 0.6809 - accuracy: 0.5492 - val_loss: 0.5692 - val_accuracy: 0.5738\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 94s 1s/step - loss: 0.6597 - accuracy: 0.6117 - val_loss: 0.5308 - val_accuracy: 0.7312\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 94s 1s/step - loss: 0.6418 - accuracy: 0.6454 - val_loss: 0.3853 - val_accuracy: 0.6762\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 93s 1s/step - loss: 0.6250 - accuracy: 0.6733 - val_loss: 0.5455 - val_accuracy: 0.7725\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 93s 1s/step - loss: 0.5764 - accuracy: 0.6904 - val_loss: 0.1541 - val_accuracy: 0.6263\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 110s 1s/step - loss: 0.5731 - accuracy: 0.6883 - val_loss: 0.5489 - val_accuracy: 0.7825\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 106s 1s/step - loss: 0.5591 - accuracy: 0.7163 - val_loss: 0.2982 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             epochs = epochs,\n",
    "                             steps_per_epoch = nb_train_samples // batch_size,\n",
    "                             validation_data = validation_generator,\n",
    "                             validation_steps = nb_validation_samples // batch_size,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 8s 304ms/step\n",
      "\n",
      " Test Result: 79.447 loss : 0.461\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(validation_generator,steps = nb_validation_samples // batch_size+1,verbose = 1)\n",
    "print(\"\\n Test Result: %.3f loss : %.3f\" %(scores[1]*100 ,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(validation_generator,nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test_samples = 800\n",
    "test_pred = model.predict_generator(test_generator,nb_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_label = np.argmax(test_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion validation Matrix\n",
      "[[279 121]\n",
      " [ 39 361]]\n",
      "Classification Validation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       swift       0.88      0.70      0.78       400\n",
      "      wagonr       0.75      0.90      0.82       400\n",
      "\n",
      "    accuracy                           0.80       800\n",
      "   macro avg       0.81      0.80      0.80       800\n",
      "weighted avg       0.81      0.80      0.80       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(\"Confusion validation Matrix\")\n",
    "print(confusion_matrix(validation_generator.classes,y_pred_label))\n",
    "print(\"Classification Validation Report\")\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k,v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes,y_pred_label,target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Test Matrix\n",
      "[[275 125]\n",
      " [ 54 346]]\n",
      "Classification Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       swift       0.84      0.69      0.75       400\n",
      "      wagonr       0.73      0.86      0.79       400\n",
      "\n",
      "    accuracy                           0.78       800\n",
      "   macro avg       0.79      0.78      0.77       800\n",
      "weighted avg       0.79      0.78      0.77       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Test Matrix\")\n",
    "print(confusion_matrix(test_generator.classes,test_pred_label))\n",
    "print('Classification Test Report')\n",
    "class_labels = test_generator.class_indices\n",
    "class_labels = {z : k for k,z in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(classification_report(test_generator.classes,test_pred_label,target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import re\n",
    "\n",
    "def draw_test(name,pred,im,true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im,160,0,0,500,cv2.BORDER_CONSTANT,value = BLACK)\n",
    "    cv2.putText(expanded_image,\"predicted - \"+pred,(20,60),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.putText(expanded_image,\"true -\"+true_label,(20,120),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow(name,expanded_image)\n",
    "    \n",
    "def getRandomImage(path,img_width,img_height):\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path,x)),os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path+\"/\"+path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path,target_size = (img_width,img_height)),final_path,path_class\n",
    "\n",
    "img_width,img_height = 100,100\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    path = '/users/dipit/Desktop/Python/CNN/CarsData/test'\n",
    "    img,final_path,true_label = getRandomImage(path,img_width,img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x*1./255\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images,batch_size = 10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0,len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    draw_test(\"Prediction\",class_labels[predictions[i][0]],image,true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
